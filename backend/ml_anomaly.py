"""
SolidTrace ML Anomaly Engine - v2.0 (REVISED)
DÃ¼zeltmeler:
  - Port 666 yazÄ±m hatasÄ± dÃ¼zeltildi â†’ merkezi SUSPICIOUS_PORTS kullanÄ±lÄ±yor
  - Multi-feature anomali tespiti eklendi (cmd_len + port + hour_of_day)
  - IsolationForest Ã§ok boyutlu Ã¶zelliklerle yeniden eÄŸitiliyor
"""

import numpy as np
import logging
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

logger = logging.getLogger("SolidTraceAPI")

# FIX: Merkezi port listesi â€” soc_engine ile senkron
SUSPICIOUS_PORTS = {4444, 5555, 6666, 7777, 8888, 9999, 1337, 31337}

# ÅžÃ¼pheli komut kelimeleri iÃ§in aÄŸÄ±rlÄ±klar
SUSPICIOUS_KEYWORDS = {
    "mimikatz": 80, "lsass": 70, "sekurlsa": 70, "procdump": 65,
    "-enc": 50, "-encodedcommand": 50,
    "psexec": 45, "wmic": 35, "winrm": 35,
    "schtasks": 30, "bcdedit": 30,
    "whoami": 20, "net user": 25, "net localgroup": 25,
}


def extract_features(event: dict) -> np.ndarray:
    """
    Event'ten Ã§ok boyutlu Ã¶zellik vektÃ¶rÃ¼ Ã§Ä±kar.
    Feature 0: Komut satÄ±rÄ± uzunluÄŸu (normalize edilmiÅŸ)
    Feature 1: Port ÅŸÃ¼phe skoru (0 veya 1)
    Feature 2: GÃ¼nÃ¼n saati anomali skoru (gece = daha ÅŸÃ¼pheli)
    Feature 3: ÅžÃ¼pheli kelime aÄŸÄ±rlÄ±k toplamÄ± (normalize edilmiÅŸ)
    """
    from datetime import datetime

    cmd = str(event.get("command_line", "") or "").lower()
    port = event.get("destination_port") or 0
    hour = datetime.utcnow().hour

    # Feature 0: Komut uzunluÄŸu (0-1 arasÄ± normalize)
    cmd_len_score = min(len(cmd) / 1000.0, 1.0)

    # Feature 1: ÅžÃ¼pheli port
    port_score = 1.0 if int(port) in SUSPICIOUS_PORTS else 0.0

    # Feature 2: Ã‡alÄ±ÅŸma saati anomalisi (22:00-06:00 = yÃ¼ksek risk)
    hour_score = 1.0 if (hour >= 22 or hour <= 6) else 0.2

    # Feature 3: ÅžÃ¼pheli kelime aÄŸÄ±rlÄ±klarÄ±
    keyword_score = min(
        sum(weight for kw, weight in SUSPICIOUS_KEYWORDS.items() if kw in cmd) / 100.0,
        1.0
    )

    return np.array([[cmd_len_score, port_score, hour_score, keyword_score]])


class MLEngine:
    """
    Multi-feature ML Anomaly Detection Engine.
    Kendini dummy data ile baÅŸlatÄ±r, Ã§alÄ±ÅŸma zamanÄ±nda yeni olaylarla gÃ¼ncellenir.
    """

    def __init__(self):
        self.scaler = StandardScaler()
        self.model = IsolationForest(
            contamination=0.1,
            random_state=42,
            n_estimators=100
        )
        self.is_ready = False
        self.event_buffer = []      # GerÃ§ek veriler birikmesi iÃ§in buffer
        self.retrain_threshold = 50  # Bu kadar gerÃ§ek event gelince yeniden eÄŸit

        self._bootstrap()

    def _bootstrap(self):
        """Dummy data ile motoru baÅŸlat (sÄ±fÄ±r downtime garantisi)"""
        try:
            # FIX: 4 boyutlu dummy data â€” gerÃ§ek feature uzayÄ±nÄ± temsil ediyor
            dummy = np.array([
                [0.0, 0.0, 0.2, 0.0],   # Normal gÃ¼n iÃ§i kÄ±sa komut
                [0.1, 0.0, 0.2, 0.0],
                [0.2, 0.0, 0.2, 0.1],
                [0.5, 0.0, 0.5, 0.2],   # Orta riskli
                [0.9, 1.0, 0.2, 0.5],   # YÃ¼ksek riskli
                [1.0, 1.0, 1.0, 0.8],   # Ã‡ok yÃ¼ksek riskli
                [1.0, 1.0, 1.0, 1.0],   # Maksimum risk
            ])
            self.scaler.fit(dummy)
            self.model.fit(self.scaler.transform(dummy))
            self.is_ready = True
            logger.info("ðŸ§  [ML_ANOMALY] Motor 4-feature dummy data ile baÅŸlatÄ±ldÄ±.")
        except Exception as e:
            logger.error(f"âš ï¸ [ML_ANOMALY] Bootstrap hatasÄ±: {e}")

    def _maybe_retrain(self):
        """Buffer dolunca gerÃ§ek verilerle yeniden eÄŸit"""
        if len(self.event_buffer) >= self.retrain_threshold:
            try:
                data = np.vstack(self.event_buffer)
                self.scaler.fit(data)
                self.model.fit(self.scaler.transform(data))
                logger.info(f"ðŸ”„ [ML_ANOMALY] {len(self.event_buffer)} gerÃ§ek event ile yeniden eÄŸitildi.")
                self.event_buffer = []  # Buffer'Ä± temizle
            except Exception as e:
                logger.error(f"âš ï¸ [ML_ANOMALY] Yeniden eÄŸitim hatasÄ±: {e}")

    def analyze(self, event: dict) -> dict:
        """Event'i analiz et, anomali skoru ve bulgular dÃ¶ndÃ¼r."""
        if not self.is_ready:
            return {"ml_score": 0, "findings": []}

        try:
            features = extract_features(event)

            # Buffer'a ekle ve gerekirse yeniden eÄŸit
            self.event_buffer.append(features)
            self._maybe_retrain()

            # Model tahmini (-1 = anomali, 1 = normal)
            scaled = self.scaler.transform(features)
            prediction = self.model.predict(scaled)[0]
            # decision_function: daha negatif = daha anormal
            anomaly_score = self.model.decision_function(scaled)[0]

            risk_score = 0
            findings = []

            # IsolationForest anomali tespiti
            if prediction == -1:
                # Skoru 0-100 arasÄ±na normalize et
                normalized = max(0, min(int((-anomaly_score) * 100), 100))
                risk_score = max(risk_score, normalized)
                findings.append({
                    "rule": "ML Anomaly",
                    "confidence": round(min((-anomaly_score) * 2, 1.0), 2),
                    "severity": "high" if normalized > 50 else "medium",
                    "details": f"IsolationForest anomaly score: {anomaly_score:.3f}"
                })

            # Kural destekli ek kontroller
            cmd = str(event.get("command_line", "") or "").lower()
            port = event.get("destination_port") or 0

            if len(cmd) > 500:
                risk_score = max(risk_score, 40)
                findings.append({
                    "rule": "ML Anomaly",
                    "confidence": 0.8,
                    "severity": "high",
                    "details": f"Unusually long command ({len(cmd)} chars)"
                })

            # FIX: ArtÄ±k merkezi SUSPICIOUS_PORTS kullanÄ±lÄ±yor
            if int(port) in SUSPICIOUS_PORTS:
                risk_score = max(risk_score, 50)
                findings.append({
                    "rule": "ML Anomaly",
                    "confidence": 0.9,
                    "severity": "critical",
                    "details": f"Known suspicious port: {port}"
                })

            return {
                "ml_score": min(risk_score, 100),
                "findings": findings
            }

        except Exception as e:
            logger.error(f"ML Analiz HatasÄ±: {e}")
            return {"ml_score": 0, "findings": []}
