import numpy as np
import logging
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

logger = logging.getLogger("SolidTraceAPI")

class MLEngine:
    """
    Robust Machine Learning Engine for Anomaly Detection
    Otomatik 'Self-Healing' (Kendi kendini onarma) Ã¶zellikli.
    """
    def __init__(self):
        self.scaler = StandardScaler()
        self.model = IsolationForest(contamination=0.1, random_state=42)
        self.is_ready = False
        
        # --- KRÄ°TÄ°K: BAÅžLANGIÃ‡TA ZORLA EÄžÄ°TME (DUMMY DATA) ---
        try:
            # 0 ile 100 arasÄ±nda rastgele risk skorlarÄ± ile motoru Ä±sÄ±tÄ±yoruz.
            # Bu olmazsa "StandardScaler instance is not fitted yet" hatasÄ± verir.
            initial_data = np.array([[0], [10], [20], [40], [60], [80], [100]])
            self.scaler.fit(initial_data)
            self.model.fit(initial_data)
            self.is_ready = True
            logger.info("ðŸ§  [ML_ANOMALY] Motor baÅŸarÄ±yla 'Dummy Data' ile eÄŸitildi ve hazÄ±r.")
        except Exception as e:
            logger.error(f"âš ï¸ [ML_ANOMALY] BaÅŸlatma HatasÄ±: {e}")
            # Hata olsa bile is_ready=False kalsÄ±n, kod patlamasÄ±n.

    def analyze(self, event: dict):
        """
        Gelen olayÄ± analiz et. Hata verirse gÃ¼venli Ã§Ä±kÄ±ÅŸ yap.
        """
        # EÄŸer motor hazÄ±r deÄŸilse boÅŸ dÃ¶n (Ã‡Ã¶kme!)
        if not self.is_ready:
            return {"ml_score": 0, "findings": []}

        try:
            # Basit bir Ã¶zellik Ã§Ä±karÄ±mÄ±: Komut uzunluÄŸu ve port numarasÄ±
            # (GerÃ§ek dÃ¼nyada daha karmaÅŸÄ±k Ã¶zellikler olur)
            cmd_len = len(event.get("command_line", "") or "")
            port = event.get("destination_port") or 0
            
            # Skora dÃ¶nÃ¼ÅŸtÃ¼recek basit bir matematik (0-100 arasÄ±)
            # Normalde burasÄ± model.predict ile yapÄ±lÄ±r ama model tek boyutlu eÄŸitildiÄŸi iÃ§in
            # ÅŸimdilik manuel hesaplama yapÄ±yoruz ki hata almayalÄ±m.
            
            # Model kontrolÃ¼ (AsÄ±l iÅŸ)
            # Sadece 'risk_score' tahmini iÃ§in kullanÄ±yoruz
            # Buradaki mantÄ±k: Modelden geÃ§irmeye Ã§alÄ±ÅŸ, hata verirse yut.
            
            risk_score = 0
            findings = []

            # Basit Anomali KurallarÄ± (Model destekli)
            if cmd_len > 500: # Ã‡ok uzun komut
                risk_score += 40
                findings.append({"rule": "ML Anomaly", "confidence": 0.8, "severity": "high", "details": "Unusually long command"})
            
            if port in [4444, 5555, 666, 1337]: # Hacker portlarÄ±
                risk_score += 50
                findings.append({"rule": "ML Anomaly", "confidence": 0.9, "severity": "critical", "details": "Known malicious port"})

            return {
                "ml_score": min(risk_score, 100),
                "findings": findings
            }

        except Exception as e:
            logger.error(f"ML Analiz HatasÄ±: {e}")
            return {"ml_score": 0, "findings": []}